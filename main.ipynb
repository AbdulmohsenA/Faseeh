{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch wandb evaluate huggingface_hub datasets evaluate numpy peft accelerate sacrebleu","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:00:49.127015Z","iopub.execute_input":"2025-06-23T23:00:49.127208Z","iopub.status.idle":"2025-06-23T23:00:52.573162Z","shell.execute_reply.started":"2025-06-23T23:00:49.127184Z","shell.execute_reply":"2025-06-23T23:00:52.572494Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.4)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nRequirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nfrom torch.utils.data import DataLoader, random_split\nfrom datasets import load_dataset, Dataset\n\n# USE RAY TUNE. https://docs.ray.io/en/latest/train/examples/intel_gaudi/bert.html\n# deepl, chatgpt translations","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:00:52.574082Z","iopub.execute_input":"2025-06-23T23:00:52.574364Z","iopub.status.idle":"2025-06-23T23:00:59.139114Z","shell.execute_reply.started":"2025-06-23T23:00:52.574334Z","shell.execute_reply":"2025-06-23T23:00:59.138317Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"import wandb\nfrom huggingface_hub import HfApi, HfFolder\nimport transformers\n\ntry: # If it is on Kaggle\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n\n    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n    WANDB_KEY = user_secrets.get_secret(\"WANDB_KEY\")\n\nexcept ModuleNotFoundError: # If it is local\n    HF_TOKEN = os.environ[\"HF_TOKEN\"]\n    WANDB_KEY = os.environ[\"WANDB_KEY\"]\n    \n\nHfFolder.save_token(HF_TOKEN)\nwandb.login(key=WANDB_KEY)\n\n\n# Reproducibility\n\nseed = 1\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntransformers.set_seed(seed)\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:00:59.139957Z","iopub.execute_input":"2025-06-23T23:00:59.140387Z","iopub.status.idle":"2025-06-23T23:01:22.464995Z","shell.execute_reply.started":"2025-06-23T23:00:59.140365Z","shell.execute_reply":"2025-06-23T23:01:22.464372Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabdulmohsena\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n2025-06-23 23:01:10.865285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750719671.033226      49 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750719671.082633      49 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\nfrom transformers import DataCollatorForSeq2Seq","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:01:22.468207Z","iopub.execute_input":"2025-06-23T23:01:22.468396Z","iopub.status.idle":"2025-06-23T23:01:30.476903Z","shell.execute_reply.started":"2025-06-23T23:01:22.468372Z","shell.execute_reply":"2025-06-23T23:01:30.476152Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# # # # Configure any model from HF HUB\n# assert input(\"YOU WILL REMOVE THE HUB MODEL FOR THIS, TYPE 'OK' TO PROCEED: \").upper() == 'OK'\n# model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n# model_name = \"facebook/m2m100_1.2B\"\n# #model_name= \"Helsinki-NLP/opus-mt-en-ar\"\n# model_name= \"facebook/nllb-200-distilled-600M\"\n\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n# generation_config = GenerationConfig(\n#     temperature=0.5,\n#     do_sample=True,\n#     max_length=256,\n#     forced_bos_token_id = 256011, # Arabic\n\n#     pad_token_id=tokenizer.pad_token_id,\n#     bos_token_id= 256011,\n#     decoder_start_token_id= 2,\n#     eos_token_id= tokenizer.eos_token_id,\n    \n# #     num_beams = 4,\n# #     early_stopping=True,\n# #     top_k=50,\n    \n# #     renormalize_logits=True,\n    \n# #     # Testing Config\n# #       repetition_penalty=0.5,\n# #     num_return_sequences=4, # Number of sentences to generate\n# #     return_dict_in_generate=True, # Returns the complete generation data from within the model.\n# #     output_scores=True, # Score of each token.\n# )\n\n# tokenizer.src_lang=\"eng_Latn\"\n# tokenizer.tgt_lang=\"arb_Arab\"\n\n# model.push_to_hub(\"Abdulmohsena/Faseeh_LoRA\")\n# tokenizer.push_to_hub(\"Abdulmohsena/Faseeh_LoRA\")\n# generation_config.push_to_hub(\"Abdulmohsena/Faseeh_LoRA\")","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:01:30.479453Z","iopub.execute_input":"2025-06-23T23:01:30.480046Z","iopub.status.idle":"2025-06-23T23:01:30.483910Z","shell.execute_reply.started":"2025-06-23T23:01:30.480026Z","shell.execute_reply":"2025-06-23T23:01:30.483173Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Instantiating The Model\nmodel_name= \"facebook/nllb-200-distilled-600M\"\n# model_name = \"Abdulmohsena/faseeh_alter\"\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name, src_lang=\"eng_Latn\", tgt_lang=\"arb_Arab\")\n# generation_config = GenerationConfig.from_pretrained(model_name)\n\ngeneration_config = GenerationConfig(\n    temperature=0.5,\n    do_sample=True,\n    max_length=256,\n    forced_bos_token_id = 256011, # Arabic\n\n    pad_token_id=tokenizer.pad_token_id,\n    bos_token_id= 256011,\n    decoder_start_token_id= 2,\n    eos_token_id= tokenizer.eos_token_id,\n    \n#     num_beams = 4,\n#     early_stopping=True,\n#     top_k=50,\n    \n#     renormalize_logits=True,\n    \n#     # Testing Config\n#       repetition_penalty=0.5,\n#     num_return_sequences=4, # Number of sentences to generate\n#     return_dict_in_generate=True, # Returns the complete generation data from within the model.\n#     output_scores=True, # Score of each token.\n)\n\ntokenizer.src_lang=\"eng_Latn\"\ntokenizer.tgt_lang=\"arb_Arab\"\n\n# https://huggingface.co/docs/transformers/en/main_classes/text_generation","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:01:30.484700Z","iopub.execute_input":"2025-06-23T23:01:30.484950Z","iopub.status.idle":"2025-06-23T23:02:00.970513Z","shell.execute_reply.started":"2025-06-23T23:01:30.484925Z","shell.execute_reply":"2025-06-23T23:02:00.969826Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14c28dc71404fa2bff1eb9324ae6f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"533edf77892149b19baa86a082811829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000db2ae2972419dbd07c227dd493cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bf5ea4656cb45dfacdf432d2434db8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee724b2e7f345cfb2a6fb06cb5cd873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6084d9ce3924022b0bccf3a16a7084e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b7cff0085e41a49e552b07187256e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177f316f068643fab3f6fdff85cbf6a6"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# # Compressing\n# from peft import get_peft_config, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training, LoraRuntimeConfig\n# from torch.profiler import profile, record_function, ProfilerActivity\n\n# ## Quantization\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_use_double_quant=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype=torch.bfloat16\n# )\n\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_name, quantization_config=bnb_config)\n\n# model.gradient_checkpointing_enable()\n# model = prepare_model_for_kbit_training(model) # prepares the whole model for kbit training\n\n# for param in model.parameters():\n#     param.requires_grad = False  # freeze the model - train adapters later\n#     if param.ndim == 1:\n#         # cast the small parameters (e.g. layernorm) to fp32 for stability\n#         param.data = param.data.to(torch.float32)\n    \n# ## Low Rank Adaptation\n# lora_config = LoraConfig(\n# #     init_lora_weights=\"olora\",\n#     use_dora=True,\n#     runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=True),\n#     task_type=TaskType.SEQ_2_SEQ_LM,\n#     inference_mode=False, \n#     r=16, \n#     lora_alpha=16, \n#     lora_dropout=0.05,\n#     target_modules=[\"k_proj\", \"q_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n# )\n\n\n# # model.enable_input_require_grads()\n# model = get_peft_model(model, lora_config)\n\n\n# # # Only train decoder weights, not encoder\n# for param in model.get_base_model().model.encoder.parameters():\n#     param.requires_grad = False\n\n# model.print_trainable_parameters()\n\n# # Pruning, not valid because we need a sparse util\n# # for name, module in model.named_modules():\n# #     if isinstance(module, (torch.nn.Linear, torch.nn.Embedding)):\n# #         prune.l1_unstructured(module, name='weight', amount=0.4)\n# #         prune.remove(module, 'weight')\n\n# # # https://huggingface.co/docs/optimum/en/concept_guides/quantization\n# # # https://huggingface.co/docs/peft/en/index\n# # # https://github.com/huggingface/peft/blob/main/examples/fp4_finetuning/finetune_fp4_opt_bnb_peft.py","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:02:00.971490Z","iopub.execute_input":"2025-06-23T23:02:00.971959Z","iopub.status.idle":"2025-06-23T23:02:00.976227Z","shell.execute_reply.started":"2025-06-23T23:02:00.971922Z","shell.execute_reply":"2025-06-23T23:02:00.975508Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Sanity Check\ndummy = \"And the Egyptian Foreign Minister assured the visitors that security is always a top priority.\"\n\nmodel = model.to('cuda')\nencoded_ar = tokenizer(dummy, return_tensors=\"pt\").to('cuda')\ngenerated_tokens = model.generate(**encoded_ar, generation_config=generation_config)\n\ntokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:02:00.977024Z","iopub.execute_input":"2025-06-23T23:02:00.977266Z","iopub.status.idle":"2025-06-23T23:02:10.451232Z","shell.execute_reply.started":"2025-06-23T23:02:00.977243Z","shell.execute_reply":"2025-06-23T23:02:10.450287Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'و أؤكد وزير الخارجية المصري للزوار أن الأمن هو دائما أولوية أساسية.'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dummy = \"spreading rumors and jokes\"\n\nmodel = model.to('cuda')\nencoded_ar = tokenizer(dummy, return_tensors=\"pt\").to('cuda')\ngenerated_tokens = model.generate(**encoded_ar, generation_config=generation_config)\n\ntokenizer.decode(generated_tokens[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:02:10.452021Z","iopub.execute_input":"2025-06-23T23:02:10.453365Z","iopub.status.idle":"2025-06-23T23:02:10.700091Z","shell.execute_reply.started":"2025-06-23T23:02:10.453345Z","shell.execute_reply":"2025-06-23T23:02:10.699319Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'يُنشر الشائعات والمزاح.'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"general_ds = load_dataset(\"allenai/nllb\", \"arb_Arab-eng_Latn\", split=\"train\", streaming=True)\nsample = general_ds.shuffle(seed=42, buffer_size=1000_000)\n\ntemp = list(sample.take(100_000))\ntemp = [t['translation'] for t in temp]\nbase_ds = Dataset.from_list(temp).rename_column(\"arb_Arab\", \"ar\").rename_column(\"eng_Latn\", \"en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:02:10.701031Z","iopub.execute_input":"2025-06-23T23:02:10.701495Z","iopub.status.idle":"2025-06-23T23:05:02.547026Z","shell.execute_reply.started":"2025-06-23T23:02:10.701468Z","shell.execute_reply":"2025-06-23T23:05:02.546407Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/38.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88abc50ec7e41469955b24a8c8c0d30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"nllb.py:   0%|          | 0.00/9.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3343515bfddb45e5890c1870188d1318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/5.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40e10c2d98d14cbd942b1dd5b122c1b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"nllb_lang_pairs.py:   0%|          | 0.00/81.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f45013452744faafd757b56ba81a15"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for allenai/nllb contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/allenai/nllb.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import re\n\nTASHKEEL_REGEX = re.compile(r\"[\\u064B-\\u0652]\")\nBRACKETS_REGEX = re.compile(r\"[\\[\\]()]\")\n\ndef no_tashkeel_or_brackets(example):\n    ar_text = example[\"ar\"]\n    return not (TASHKEEL_REGEX.search(ar_text) or BRACKETS_REGEX.search(ar_text))\n\nfiltered_dataset = base_ds.filter(no_tashkeel_or_brackets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:02.547813Z","iopub.execute_input":"2025-06-23T23:05:02.548050Z","iopub.status.idle":"2025-06-23T23:05:03.070432Z","shell.execute_reply.started":"2025-06-23T23:05:02.548031Z","shell.execute_reply":"2025-06-23T23:05:03.069737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f61d1dccb02401fa3824a091dc6568b"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"filtered_dataset[444]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:03.071218Z","iopub.execute_input":"2025-06-23T23:05:03.071478Z","iopub.status.idle":"2025-06-23T23:05:03.076935Z","shell.execute_reply.started":"2025-06-23T23:05:03.071457Z","shell.execute_reply":"2025-06-23T23:05:03.076339Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'ar': 'الا ان الميزانية التي اعلنت في 22 اذار مارس لم تذكر اي تغييرات في النظام القائم.',\n 'en': 'But the budget, announced on March 22, makes no mention of changes to the existing regime.'}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from datasets import concatenate_datasets\n\ndataset = load_dataset(\"Abdulmohsena/Classic-Arabic-English-Language-Pairs\")\n\ndataset = concatenate_datasets([\n    dataset['quran'],\n    dataset['hadith'],\n    dataset['books']\n])\n\ndataset = dataset.shuffle(seed=42)","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:05:03.077754Z","iopub.execute_input":"2025-06-23T23:05:03.078014Z","iopub.status.idle":"2025-06-23T23:05:09.284047Z","shell.execute_reply.started":"2025-06-23T23:05:03.077989Z","shell.execute_reply":"2025-06-23T23:05:09.283456Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/952 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f4a4ded2d4840ef9cc4784948347df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"quran-00000-of-00001.parquet:   0%|          | 0.00/818k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4fa786457084e00a058a910e0b48447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hadith-00000-of-00001.parquet:   0%|          | 0.00/644k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24f75412966a4ca7963eb92063b90e55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"books-00000-of-00001.parquet:   0%|          | 0.00/3.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370e44d98f5d4f8891676cc6866cf77d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating quran split:   0%|          | 0/9474 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"950d81353a1a4a38ac3cba82522250ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating hadith split:   0%|          | 0/4107 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e703491dbf4d7ebcaae4598ef3b88e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating books split:   0%|          | 0/13331 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62d753aee5be4ade80696d515375a5d7"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"complete_dataset = concatenate_datasets([filtered_dataset, dataset]).shuffle(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:09.284909Z","iopub.execute_input":"2025-06-23T23:05:09.285147Z","iopub.status.idle":"2025-06-23T23:05:09.316804Z","shell.execute_reply.started":"2025-06-23T23:05:09.285129Z","shell.execute_reply":"2025-06-23T23:05:09.316127Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(f\"Base dataset for stability: {filtered_dataset.num_rows / (complete_dataset.num_rows):.2%}\")\nprint(f\"Styled dataset for style and quality: {dataset.num_rows / (complete_dataset.num_rows):.2%}\")\n\nratio_str = f\"{(filtered_dataset.num_rows / complete_dataset.num_rows) * 100:.0f}_{(dataset.num_rows / complete_dataset.num_rows) * 100:.0f}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:09.317745Z","iopub.execute_input":"2025-06-23T23:05:09.317999Z","iopub.status.idle":"2025-06-23T23:05:09.322230Z","shell.execute_reply.started":"2025-06-23T23:05:09.317976Z","shell.execute_reply":"2025-06-23T23:05:09.321559Z"}},"outputs":[{"name":"stdout","text":"Base dataset for stability: 73.40%\nStyled dataset for style and quality: 26.60%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"complete_dataset[111]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:09.322871Z","iopub.execute_input":"2025-06-23T23:05:09.323123Z","iopub.status.idle":"2025-06-23T23:05:09.340137Z","shell.execute_reply.started":"2025-06-23T23:05:09.323101Z","shell.execute_reply":"2025-06-23T23:05:09.339423Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'ar': 'في عام 1492، كان عدد قليل منهم قد نظر إلى مدن العالم، ويعتقد أن أوروبا سوف تأتي للسيطرة على قرون التجارة العالمية في وقت لاحق.',\n 'en': 'In 1492, few would have looked at the cities of the world and believed that Europe would come to dominate global trade centuries later.'}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"preprocess_function = lambda examples: tokenizer(\n        examples['en'], text_target=examples['ar'], max_length=256, truncation=True, padding=True, return_tensors='pt')\n\ntokenized_dataset = complete_dataset.map(preprocess_function, batched=True)\ntokenized_dataset = tokenized_dataset.train_test_split(test_size=0.20, seed=42)","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:05:09.340944Z","iopub.execute_input":"2025-06-23T23:05:09.341227Z","iopub.status.idle":"2025-06-23T23:05:39.587468Z","shell.execute_reply.started":"2025-06-23T23:05:09.341203Z","shell.execute_reply":"2025-06-23T23:05:39.586946Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/101159 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116ecda7cb224cf88b9d629cb21b3939"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2025-06-23T23:05:39.588187Z","iopub.execute_input":"2025-06-23T23:05:39.588387Z","iopub.status.idle":"2025-06-23T23:05:39.591956Z","shell.execute_reply.started":"2025-06-23T23:05:39.588370Z","shell.execute_reply":"2025-06-23T23:05:39.591260Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Reward model","metadata":{}},{"cell_type":"code","source":"from evaluate import load\nsacrebleu = load(\"sacrebleu\")\n\ndef postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [[label.strip()] for label in labels]\n\n        return preds, labels\n\ndef compute_metrics(eval_preds):\n        preds, labels = eval_preds\n        if isinstance(preds, tuple):\n            preds = preds[0]\n        preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n        # Some simple post-processing\n        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n        bleu_score = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)['score']\n        #fluency_score = fluency.compute(texts=decoded_preds)['classical_score']\n        \n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n\n        result = {\n                    \"bleu\": bleu_score,\n                    #\"fluency\": fluency_score,\n                    \"gen_len\": np.mean(prediction_lens)\n                }\n        \n        result = {k: round(v, 4) for k, v in result.items()}\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:39.593744Z","iopub.execute_input":"2025-06-23T23:05:39.594271Z","iopub.status.idle":"2025-06-23T23:05:43.010378Z","shell.execute_reply.started":"2025-06-23T23:05:39.594245Z","shell.execute_reply":"2025-06-23T23:05:43.009688Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0055f353528a461fb5478ca6c3acfbb5"}},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## TEST","metadata":{}},{"cell_type":"code","source":"# Freeze until convergence then unfreeze\n\nfor param in model.get_encoder().parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:43.013732Z","iopub.execute_input":"2025-06-23T23:05:43.014756Z","iopub.status.idle":"2025-06-23T23:05:43.019487Z","shell.execute_reply.started":"2025-06-23T23:05:43.014728Z","shell.execute_reply":"2025-06-23T23:05:43.018797Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom datetime import datetime\n\ntraining_args = Seq2SeqTrainingArguments(\n        output_dir=\"faseeh_alter\",\n        eval_strategy=\"epoch\",\n        weight_decay=0.01,\n        warmup_steps=1_000,\n        learning_rate=5e-5,\n        lr_scheduler_type=\"cosine\",\n        per_device_train_batch_size=6,\n        per_device_eval_batch_size=6,\n        save_total_limit=2,\n        num_train_epochs=5,\n        predict_with_generate=True,\n        seed = 42,\n        report_to=\"wandb\",\n        run_name=f'{datetime.now()}',\n        logging_strategy = 'steps',\n        logging_steps = 300,\n        # load_best_model_at_end = True,\n\n\n\n        # fp16=True,\n        push_to_hub=True,\n    )\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'] ,\n    eval_dataset=tokenized_dataset['test'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:05:43.020147Z","iopub.execute_input":"2025-06-23T23:05:43.020372Z","iopub.status.idle":"2025-06-23T23:05:44.768933Z","shell.execute_reply.started":"2025-06-23T23:05:43.020339Z","shell.execute_reply":"2025-06-23T23:05:44.768188Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_49/2939897815.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:06:12.004341Z","iopub.execute_input":"2025-06-23T23:06:12.005020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250623_230612-nd9mirnn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/abdulmohsena/huggingface/runs/nd9mirnn' target=\"_blank\">2025-06-23 23:05:44.519015</a></strong> to <a href='https://wandb.ai/abdulmohsena/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/abdulmohsena/huggingface' target=\"_blank\">https://wandb.ai/abdulmohsena/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/abdulmohsena/huggingface/runs/nd9mirnn' target=\"_blank\">https://wandb.ai/abdulmohsena/huggingface/runs/nd9mirnn</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='56' max='67440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   56/67440 00:37 < 12:59:38, 1.44 it/s, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"artifact = wandb.Artifact(\n    name=\"Faseeh_thaw_\" + ratio_str,\n    type=\"model\"\n)\n\n# Add the directory (where trainer saved the model)\nartifact.add_dir(training_args.output_dir)  # or training_args.output_dir\n\n# Log the artifact\nwandb.log_artifact(artifact)\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch.profiler as profiler\n# with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA]) as prof:\n    \n\n# print(prof.key_averages().table(sort_by=\"cuda_time_total\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T19:34:46.334296Z","iopub.status.idle":"2025-06-14T19:34:46.334584Z","shell.execute_reply.started":"2025-06-14T19:34:46.334437Z","shell.execute_reply":"2025-06-14T19:34:46.334451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}